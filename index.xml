<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Tim Stuart</title>
    <link>/</link>
    <description>Recent content in Home on Tim Stuart</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Retrieving SRA data from AWS Glacier storage</title>
      <link>/blog/sra-aws/</link>
      <pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/sra-aws/</guid>
      <description>The SRA now hosts the user-submitted files for download alongside the “SRA” version. This is useful because the SRA version strips some information like original read names and the index read, which are commonly used to store cell barcode information for single-cell data.
However, the user-submitted files are not quite as easy to access as the SRA files. They are stored on GCP and AWS. Transfer of the files to other cloud storage (eg, to your own S3 bucket) is free, but users pay the cost of egress if you want to use local compute resources.</description>
    </item>
    
    <item>
      <title>Downloading SRA data via GCP</title>
      <link>/blog/downloading-sra-data-via-gcp/</link>
      <pubDate>Mon, 14 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/downloading-sra-data-via-gcp/</guid>
      <description>The SRA now stores the data in the originally uploaded format for many SRA accessions. This is particularly useful for single-cell data, as the conversion to SRA FASTQ often strips cell barcodes from the file, as read names and read tags are not preserved. SRA enables you to download the original files provided by the authors, provided you pay for the download cost. They provide download links for AWS and Google Cloud Compute.</description>
    </item>
    
    <item>
      <title>Single-cell ATAC &#43; RNA co-assay methods</title>
      <link>/blog/single-cell-atac-rna/</link>
      <pubDate>Thu, 29 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/single-cell-atac-rna/</guid>
      <description>Several methods have been developed over the past ~2 years that enable the simultaneous measurement of DNA accessibility and gene expression in single cells. To me, these co-assay methods are one of the most exciting frontiers in single-cell biology, and will open up a range of new approaches for studying gene regulation.
These new single-cell co-assay methods include sciCAR, scCAT-seq, SNARE-seq, Paired-seq, ASTAR-seq, SHARE-seq, and a recently released commercial solution by 10x Genomics.</description>
    </item>
    
    <item>
      <title>Iterative epigenomic analyses of the same single cell</title>
      <link>/blog/iterative-epigenomic-analyses/</link>
      <pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/iterative-epigenomic-analyses/</guid>
      <description>https://doi.org/10.1101/2020.07.20.212969
Epigenomic measurements are typically destructive, and so prevent the identification of multiple marks at the same site in the same single cell. For example, CUT&amp;amp;Tag (Kaya-Okur et al. 2019; Carter et al. 2019) uses Tn5 transposase guided by an antibody to tagment DNA near the antibody binding site, which is then sequenced and mapped to determine the position of the mark in the cell.
Ohnuki et al. present an innovative new method that gets around this limitation in some interesting ways (Ohnuki et al.</description>
    </item>
    
    <item>
      <title>Seeking the K99</title>
      <link>/blog/seeking-the-k99/</link>
      <pubDate>Tue, 07 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/seeking-the-k99/</guid>
      <description>In February 2020 I submitted an application for the NIH K99/R00 career development award. This is an award designed to help senior postdocs transition into an independent position, and is something many postdocs in the US consider applying for. Applying for the K99 is tough, there are a lot of application components and people involved, and you need to develop a solid 5-year research and training plan. In this post I&amp;rsquo;ll describe my experience in applying for the K99 and try to offer some advice for future applicants.</description>
    </item>
    
    <item>
      <title>Community detection</title>
      <link>/blog/community-detection/</link>
      <pubDate>Fri, 03 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/community-detection/</guid>
      <description>A major goal of single-cell analysis is to study the cell-state heterogeneity within a sample by discovering groups within the population of cells. This amounts to a clustering problem, where we aim to learn an optimal set of groups (communities) from the observed data. In single-cell biology we often use graph-based community detection methods to do this, as these methods are unsupervised, scale well, and usually give good results.</description>
    </item>
    
    <item>
      <title>Reflections on a paper a day</title>
      <link>/blog/reflections-on-a-paper-a-day/</link>
      <pubDate>Sun, 07 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/reflections-on-a-paper-a-day/</guid>
      <description>Four years ago I read a paper a day for almost a year. Two things stood out to me from the experience: (1) the sense that there is an insurmountable number of papers that need to be read to keep on top of the literature completely disappears when you do this, and (2) holding yourself to reading a paper every day (seven days a week) is a terrible and demoralizing idea.</description>
    </item>
    
    <item>
      <title>Installing PyTorch</title>
      <link>/blog/installing-pytorch/</link>
      <pubDate>Sun, 05 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/installing-pytorch/</guid>
      <description>See the PyTorch website: https://pytorch.org/tutorials/
1. Install miniconda I find minoconda3 is the easiest way to get everything installed and working for pytorch. Install the python 3.7 64 bit linux version from here:
https://docs.conda.io/en/latest/miniconda.html
 2. Create a conda environment It’s a good idea to use a separate environment for different projects. Create a new conda environment for deep learning stuff:
conda create --name cnn  3. Activate the conda environment conda activate cnn  4.</description>
    </item>
    
    <item>
      <title>Grouping scATAC-seq reads</title>
      <link>/blog/sinto/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/sinto/</guid>
      <description>Often in the analysis of single-cell ATAC-seq data it&amp;rsquo;s helpful to create a &amp;ldquo;pseudo-bulk&amp;rdquo; accessibility profile for each individual cell type or cluster within the dataset. This can allow visualization of the separate accessibility tracks, and peak-calling on the pure cell types that can often enable the identification of rare peaks that are obscured when looking at the whole population.
However, there are few tools I know of that provide a nice solution to the basic problem of splitting a BAM file into given groups of cell barcodes.</description>
    </item>
    
    <item>
      <title>bioRxiv 2017 update</title>
      <link>/blog/biorxiv-2017-update/</link>
      <pubDate>Wed, 04 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/biorxiv-2017-update/</guid>
      <description>collection_date &amp;lt;- ymd(&amp;quot;2017_10_04&amp;quot;) dat &amp;lt;- fread(&amp;quot;~/Documents/GitHub/biorxivData/data/biorxiv_data_2017_10_04.tsv&amp;quot;) %&amp;gt;% mutate(Age = collection_date - ymd(`Original submission`), Revised = `Original submission` != `Current submission`) Submissions over time weekly &amp;lt;- dat %&amp;gt;% mutate(weeks_past = ceiling(Age / 7), `Submission week` = collection_date - weeks(weeks_past)) %&amp;gt;% group_by(`Submission week`) %&amp;gt;% summarise(Submissions = n()) ggplot(weekly, aes(`Submission week`, Submissions)) + geom_point(stat = &amp;quot;identity&amp;quot;) + geom_smooth() + ggtitle(&amp;quot;bioRxiv submissions per week&amp;quot;) + theme_bw() Last year the number of weekly submissions peaked at around 60, now it’s 5x higher hitting 300 per week earlier in 2017.</description>
    </item>
    
    <item>
      <title>Bioinformatics snippets</title>
      <link>/blog/useful-bio/</link>
      <pubDate>Thu, 14 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/useful-bio/</guid>
      <description>Trim reads cutadapt -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC -o output.fq.gz input.fq.gz  Map RNA-seq # build index STAR --runThreadN 10 \ --runMode genomeGenerate \ --genomeDir genome \ --genomeFastaFiles genome.fa \ --sjdbGTFfile genes.gtf # map STAR --runThreadN 20 \ --genomeDir genome \ --alignIntronMax 5000 \ --alignIntronMin 10 \ --readFilesCommand zcat \ --readFilesIn input.fq.gz  Pseudomap RNA-seq with kallisto # build index kallisto index -i index.idx Arabidopsis_thaliana.TAIR10.cds.all.fa #quantify for filename in *.fq.gz; do samplename=(${filename//.</description>
    </item>
    
    <item>
      <title>Using python decorators</title>
      <link>/blog/2017-04-09-using-python-decorators/</link>
      <pubDate>Sun, 09 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/2017-04-09-using-python-decorators/</guid>
      <description>Yesterday I wrote my first python decorator. Decorators have always seemed a bit mysterious to me, but having finally written one I can see a bit better how they work. This is the decorator I wrote:
def log_info(func): def wrapper(args): print(&amp;quot;Function {} called with the following arguments:\n&amp;quot;.format(func.__name__)) for arg in vars(args): print(str(arg) + &amp;#39;\t&amp;#39; + str(getattr(args, arg))) t1 = time.time() func(args) t2 = time.time() elapsed = [round(x, 2) for x in divmod(t2-t1, 60)] print(&amp;quot;\nFunction completed in {} m {} s\n&amp;quot;.</description>
    </item>
    
    <item>
      <title>Create a computational lab notebook with bookdown</title>
      <link>/blog/2017-04-03-comp-notebook/</link>
      <pubDate>Mon, 03 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/2017-04-03-comp-notebook/</guid>
      <description>Every data analysis I do now is kept in an R Markdown document. These are great for mixing code with explanatory text, and you can run code in many languages not just R. Whenever I finished working on something, I would compile the R Markdown document into a self-contained html report and save is somewhere, usually with a descriptive filename like &amp;ldquo;coverage_genes&amp;rdquo; or &amp;ldquo;col_vs_cvi&amp;rdquo;.
This is where the problems begin. These reports, while great individually, can quickly pile up and you start to realize that the name &amp;ldquo;coverage_genes&amp;rdquo; doesn&amp;rsquo;t really help you find a bit of code you wrote 3 weeks ago.</description>
    </item>
    
    <item>
      <title>Installing Magic</title>
      <link>/blog/2017-03-03-installing-magic/</link>
      <pubDate>Fri, 03 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/2017-03-03-installing-magic/</guid>
      <description>Installing magic Recently a method for imputing single cell gene expression matricies was posted on biorxiv by David van Dijk et al., called magic (Markov Affinity-based Graph Imputation of Cells). I&amp;rsquo;ve been analysing single cell RNA-seq data recently, and this method looks like it could be useful when trying to find co-transcriptional networks, as single cell data suffers from dropout which makes finding co-transcriptional networks hard.
I had lots of problems getting magic installed and running, so will document them here for future reference.</description>
    </item>
    
    <item>
      <title>R demo</title>
      <link>/blog/r_demo/</link>
      <pubDate>Thu, 22 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/r_demo/</guid>
      <description>Getting started Clone the repo if you haven’t already:
git clone https://github.com/timoast/dac.git Install RStudio.
Install the following packages:
install.packages(c(&amp;quot;readr&amp;quot;, &amp;quot;tidyr&amp;quot;, &amp;quot;data.table&amp;quot;, &amp;quot;dplyr&amp;quot;, &amp;quot;ggplot2&amp;quot;)) library(readr) library(data.table) library(ggplot2) library(tidyr) All the following code will assume you are in the directory that holds this file (r_demo.rmd) in the github repo (ie dac/code/).
 Importing Data The readr way Some docs
library(readr) read_tsv(&amp;quot;../data/r_demo/coverages.tsv&amp;quot;, col_names = c(&amp;quot;Accession&amp;quot;, &amp;quot;Coverage&amp;quot;)) ## Parsed with column specification: ## cols( ## Accession = col_character(), ## Coverage = col_double() ## ) ## # A tibble: 216 x 2 ## Accession Coverage ## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; ## 1 Aa-0 41 ## 2 Abd-0 67 ## 3 Ag-0 47 ## 4 Ak-1 38 ## 5 Alst-1 42 ## 6 Altai-5 42 ## 7 Amel-1 60 ## 8 An-1 39 ## 9 Ang-0 48 ## 10 Anholt-1 53 ## # … with 206 more rows # also works for gzipped files read_tsv(&amp;quot;.</description>
    </item>
    
    <item>
      <title>smRNA analysis notes</title>
      <link>/blog/2016-07-12-smrna-analysis/</link>
      <pubDate>Tue, 12 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-07-12-smrna-analysis/</guid>
      <description>I recently analysed some smRNA data for a paper I&amp;rsquo;m working on. These are my analysis notes.
I used previously published data for Brachypodium, from this paper:
Garvin DF, Schmutz J, Rokhsar D, Bevan MW, Barry K, Lucas S, et al. Genome sequencing and analysis of the model grass Brachypodium distachyon. Nature. 2010;463: 763–768. doi:10.1038/nature08747
First step is to download the data:
$ wget ftp://ftp-trace.ncbi.nlm.nih.gov//sra/sra-instant/reads/ByStudy/sra/SRP/SRP001/SRP001895/SRR035616/SRR035616.sra $ fastq-dump SRR035616.sra $ pigz SRR035616.</description>
    </item>
    
    <item>
      <title>WGBS Analysis notes -- BS-seeker2</title>
      <link>/blog/2016-03-29-bsseeker2/</link>
      <pubDate>Tue, 29 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-03-29-bsseeker2/</guid>
      <description>Whole genome bisulfite sequencing analysis notes for BS-seeker2.  Step 1: Trim adapters and low quality bases Illumina TruSeq adapter sequence: GATCGGAAGAGCACACGTCTGAACTCCAGTCAC
cutadapt -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC -m 50 reads.fastq \ | seqtk trimfq -l 50 - \ | pigz &amp;gt; filtered_reads.fq.gz  Step 2: Quality control This step can also be performed on the unfiltered fastq file to compare output before and after read trimming.
fastqc filtered_reads.fq.gz  Step 3: Alignment 3.</description>
    </item>
    
    <item>
      <title>bioRxiv</title>
      <link>/blog/2016-03-01-biorxiv/</link>
      <pubDate>Tue, 01 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-03-01-biorxiv/</guid>
      <description>After posting a my first preprint to bioRxiv a few weeks ago, I have been periodically checking the number of views and PDF downloads. I became interested to see how many downloads or views the preprints on bioRxiv typically get, but this type of information isn’t actually available. What are the all-time top bioRxiv preprints? How many people are reading bioRxiv preprints on average? No-one knows! Altmetric must track this data, as it will tell you how a particular preprint ranks in relation to others, but that data hasn’t been made publicly available (as far as I can tell).</description>
    </item>
    
    <item>
      <title>A paper a day</title>
      <link>/blog/2016-02-23-papers/</link>
      <pubDate>Tue, 23 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-02-23-papers/</guid>
      <description>In an effort to read more papers this year, I&amp;rsquo;m going to read a paper (or something paper-like) each day for the remainder of the year, and post each paper below as I go.
Dec 31 Galanter JM, Gignoux CR, Oh SS, Torgerson D, Pino-Yanes M, Thakur N, et al. Differential methylation between ethnic sub-groups reflects the effect of genetic ancestry and environmental exposures. eLife. doi:10.7554/eLife.20532
Dec 30 Lun ATL, McCarthy DJ, Marioni JC.</description>
    </item>
    
    <item>
      <title>Lorne Genome 2016 presentation</title>
      <link>/blog/2016-02-18-lorne/</link>
      <pubDate>Thu, 18 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-02-18-lorne/</guid>
      <description>This week I presented some recent work at the Lorne Genome conference. It was my first time at Lorne and it&amp;rsquo;s a fantastic meeting with lots of interesting talks. It was great to see so many people getting interested in transposon biology too!
Here are a few links to the work I was presenting:
TEPID TE presence/absence variant discovery software:
https://github.com/ListerLab/TEPID
Poster:
https://dx.doi.org/10.6084/m9.figshare.2082757.v1
Manuscript:
http://dx.doi.org/10.1101/039511</description>
    </item>
    
    <item>
      <title>Extract reads from bam file by read name</title>
      <link>/blog/2015-10-12-extractreads/</link>
      <pubDate>Mon, 12 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>/blog/2015-10-12-extractreads/</guid>
      <description>While there are very fast and easy ways to extract reads from a bam file according to mapping location, extracting reads by read name is more difficult.
Simple methods, like using grep, are incredibly slow if you want to look for more than a few reads.
Luckily, pysam allows you to index a bam file by read name (using pysam.IndexedReads(AlignmentFile)) while keeping the sort order. However, the index is stored in memory so this can use a lot of RAM (my tests with a 5.</description>
    </item>
    
    <item>
      <title>Estimation of insert size from sam / bam files</title>
      <link>/blog/2014-11-04-sizeestimation/</link>
      <pubDate>Tue, 04 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/blog/2014-11-04-sizeestimation/</guid>
      <description>I&amp;rsquo;ve been looking for a simple way to estimate paired-end insert sizes from mapped data. There are a few more complicated tools available (I think picard will do it), as well as simple scripts different people have written that don&amp;rsquo;t exclude outliers. However outliers due to discordant read alignments will hugely change the mean, so need to be removed.
As I couldn&amp;rsquo;t find anything that was a nice middle ground, I ended up writing my own simple python script that will take input from stdin and exclude outliers more that two standard deviations from the median, and print the mean and standard deviation to stdout.</description>
    </item>
    
    <item>
      <title>MethyC-Seq Analysis Notes</title>
      <link>/blog/2014-10-29-methyc-analysis/</link>
      <pubDate>Wed, 29 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/blog/2014-10-29-methyc-analysis/</guid>
      <description>Preliminary steps Bcl-conversion  Enter a screen  screen -S bcl-conversion Navigate to directory with run (eg. 130909_SNL119_0105_AC2GYKACXX) Check sample sheet configured correctly. If only one adapter in lane, remove adapter sequence from sample sheet. Run the following (modified with correct run name, sample sheet etc). Can change final value to change number of reads in files:  /usr/local/packages/CASAVA_v1.8.2/bcl2fastq/build/bin/configureBclToFastq.pl --input-dir /dd_rundata/hiseq/Runs/130909_SNL119_0105_AC2GYKACXX/Data/Intensities/BaseCalls/ --sample-sheet /dd_rundata/hiseq/Runs/130909_SNL119_0105_AC2GYKACXX/SampleSheet.csv --fastq-cluster-count 50000000 Navigate to newly created Unaligned directory (under top run directory) and enter:  nohup make -j 12 Moving and renaming files  Copy run files from run directory to working directory:  cp Project_E_grandis ~/working_data Rename fastq files to s_1_sequence.</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/publications/</guid>
      <description>Google Scholar
2022   Nanobody-tethered transposition allows for multifactorial chromatin profiling at single-cell resolution  Tim Stuart, Stephanie Hao, Bingjie Zhang, Levan Mekerishvili, Dan Landau, Silas Maniatis, Rahul Satija, Ivan Raimondi  bioRxiv. 2022  PDF bioRxiv         Dictionary Learning for Integrative, Multimodal, and Scalable Single-Cell Analysis.  Yuhan Hao, Tim Stuart, Madeline Kowalski, Saket Choudhary, Paul Hoffman, Austin Hartman, Avi Srivastava, Gesmira Molla, Shaista Madad, Carlos Fernandez-Granda, and Rahul Satija  bioRxiv.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/research/</guid>
      <description>Many human genetic diseases involve multiple causal loci in noncoding regions of the genome, implicating mutations in regulatory elements rather than protein-coding genes as the cause of these diseases. Deciphering the etiology of these human genetic diseases requires an understanding of how genes are regulated to develop and maintain functional cell states. This regulation is encoded both through chromatin state, and genetically encoded in the DNA sequence of regulatory elements such as enhancers, promoters, silencers, and insulators.</description>
    </item>
    
    <item>
      <title>Software</title>
      <link>/software/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/software/</guid>
      <description>  I contribute to the following software packages:
Signac Signac is an R toolkit for the analysis of single-cell chromatin data.
 Docs GitHub CRAN  Seurat Seurat is an R toolkit for the analysis of single-cell RNA-seq data.
 Docs GitHub CRAN  Sinto Sinto is a Python package for processing aligned single-cell reads.
 Docs GitHub PyPI  </description>
    </item>
    
  </channel>
</rss>
